<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Pytorch基础知识（一） | MuXiaoChen🍊</title><meta name="keywords" content="Pytorch,Machine Learning,Deep Learning"><meta name="author" content="MuXiaoChen🍊,1554267532@qq.com"><meta name="copyright" content="MuXiaoChen🍊"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="本文主要是介绍有关Pytorch的基础知识（一）"><meta property="og:type" content="article"><meta property="og:title" content="Pytorch基础知识（一）"><meta property="og:url" content="https://miraii.cn/posts/5a986f0/"><meta property="og:site_name" content="MuXiaoChen🍊"><meta property="og:description" content="本文主要是介绍有关Pytorch的基础知识（一）"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.aimiliy.top/articleBackground/article6.webp"><meta property="article:published_time" content="2024-07-02T08:39:08.000Z"><meta property="article:modified_time" content="2025-05-29T15:23:47.806Z"><meta property="article:author" content="MuXiaoChen🍊"><meta property="article:tag" content="Pytorch"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Deep Learning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.aimiliy.top/articleBackground/article6.webp"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://miraii.cn/posts/5a986f0/"><link rel="preconnect" href="//cdn.aimiliy.top"><link rel="preconnect" href="//img.aimiliy.top"><link rel="preconnect" href="//umami.aimiliy.top"><link rel="preconnect" href="//busuanzi.aimiliy.top"><meta name="baidu-site-verification" content="codeva-JLcaXpJvSI"><meta name="baidu-site-verification" content="codeva-XXU4K1uicS"><link rel="stylesheet" href="/css/index.css?v=1.8.39"><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/font-awesome/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/swiper@11.2.6-c/swiper-bundle.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="/css/swiperstyle.css?v=1.8.39" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/hexo-butterfly-tag-plugins-plus/font-awesome-animation.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/aplayer@1.10.1/APlayer.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/toastify@1.12.0/toastify.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.aimiliy.top/npm/fancybox@5.0.36/fancybox.min.css" media="print" onload='this.media="all"'><script async src="https://umami.aimiliy.top/script.js" data-website-id="3348d0ad-813b-4d17-98d2-d5404445f786"></script><script>const GLOBAL_CONFIG={root:"/",algolia:{appId:"TMAQULEA61",apiKey:"cbdc736a26353ade14da768f54cde1fe",indexName:"MuXiaoChen",hitsPerPage:6,languages:{input_placeholder:"搜索文章",hits_empty:"未找到符合您查询的内容：${query}",hits_stats:"找到 ${hits} 条结果，耗时 ${time} 毫秒"}},localSearch:void 0,translate:void 0,noticeOutdate:{limitDay:365,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:300,highlightFullpage:!0,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!0,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.aimiliy.top/npm/infinitegrid@4.12.0/infinitegrid.min.js",buttonText:"加载更多"},countUp:{js:"https://cdn.aimiliy.top/npm/js/countup.js"},toast:{js:"https://cdn.aimiliy.top/npm/toastify@1.12.0/toastify.js"},isPhotoFigcaption:!1,islazyloadPlugin:!0,isAnchor:!1,percent:{toc:!0}}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Pytorch基础知识（一）",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-05-29 23:23:47"}</script><script>(()=>{window.saveToLocal={set:(e,t,o)=>{if(!o)return;const r=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:r}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:r}=JSON.parse(t);if(!(Date.now()>r))return o;localStorage.removeItem(e)}},window._scriptCache={},window.getScript=(e,t={})=>{if(window._scriptCache[e])return window._scriptCache[e];const o=new Promise(((o,r)=>{if(document.querySelector(`script[src="${e}"]`)){if("complete"===document.readyState)o();else{const e=()=>{"complete"===document.readyState&&(o(),document.removeEventListener("readystatechange",e))};document.addEventListener("readystatechange",e)}return}const a=document.createElement("script");a.src=e,a.async=!0,Object.entries(t).forEach((([e,t])=>a.setAttribute(e,t))),a.onload=()=>o(),a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||o()},a.onerror=()=>r(new Error(`Script load error: ${e}`)),document.head.appendChild(a)}));return window._scriptCache[e]=o,o},window.btf={addGlobalFn:(e,t,o=!1,r=window)=>{const a=r.globalFn||{};a[e]=a[e]||{},a[e][o||Object.keys(a[e]).length]=t,r.globalFn=a},map:new Map([["red","rgb(241, 71, 71)"],["orange","rgb(241, 162, 71)"],["yellow","rgb(241, 238, 71)"],["purple","rgb(179, 71, 241)"],["blue","rgb(102, 204, 255)"],["gray","rgb(226, 226, 226)"],["green","rgb(57, 197, 187)"],["whitegray","rgb(241, 241, 241)"],["pink","rgb(237, 112, 155)"],["black","rgb(0, 0, 0)"],["darkblue","rgb(97, 100, 159)"],["heoblue","rgb(66, 90, 239)"]]),initItem:e=>{const t={blogbg:"default",universe:"block",blur:"0",fpson:"1",transNum:"85",blurRad:"20",font:"LXGW",themeColor:"green",rs:"block",mouse:"on",light:"true",snow:"none",aside:"1",asidePos:"1",nav:"0",defaultMusic:JSON.stringify(e),localMusic:JSON.stringify(e)};Object.entries(t).forEach((([e,t])=>{localStorage.getItem(e)!==t&&localStorage.setItem(e,t)})),localStorage.removeItem("shuffledPlaylist"),localStorage.removeItem("shuffledMusicList")},setCssVariable:(e,t)=>{document.documentElement.style.setProperty(e,t)}};const e=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},t=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};window.activateDarkMode=e,window.activateLightMode=t;const o=saveToLocal.get("theme"),r=(new Date).getHours();void 0===o?r<=6||r>=18?e():t():"light"===o?t():e();/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple");const a=()=>{const e=(e,t,o,r)=>{const a=localStorage.getItem(e),n=Number(a);(null===a||""===a.trim()||isNaN(n)||n<t||n>o)&&localStorage.setItem(e,r)};[{key:"universe",list:["block","none"],def:"block"},{key:"snow",list:["block","none"],def:"none"},{key:"rs",list:["block","none"],def:"block"},{key:"mouse",list:["on","off"],def:"on"},{key:"light",list:["true","false"],def:"true"},{key:"aside",list:["1","0"],def:"1"},{key:"asidePos",list:["1","0"],def:"1"},{key:"nav",list:["1","0"],def:"0"},{key:"blur",list:["1","0"],def:"0"},{key:"fpson",list:["1","0"],def:"1"}].forEach((e=>((e,t,o)=>{const r=localStorage.getItem(e);t.includes(r)||localStorage.setItem(e,o)})(e.key,e.list,e.def))),e("transNum",0,100,"85"),e("blurRad",0,100,"20");const t=localStorage.getItem("font");"default"===t||["YSHST","MiSans","HYTMR","LXGW","TTQHB","Consolas_1","ZhuZiAWan"].includes(t)||localStorage.setItem("font","LXGW");const o=localStorage.getItem("themeColor");btf.map.has(o)||localStorage.setItem("themeColor","green")};var n,l;n="v2.71",null===(l=localStorage.getItem("MuXiaoChenVersion"))||l!==n?(localStorage.setItem("MuXiaoChenVersion","v2.71"),btf.initItem({id:"7397995017",type:"playlist",server:"tencent"})):a(),setTimeout(console.log.bind(console,"\n %c 🌐系统缓存检查完毕！\n","color: white; background: #4facfe; padding:5px 0; border-radius: 5px;"));const s=localStorage,c=document.documentElement,i=c.style;c.classList.toggle("hide-aside","1"!==s.getItem("aside")),c.classList.toggle("nav-sticky","1"===s.getItem("nav")),c.classList.toggle("bg-filter","0"!==s.getItem("blur")),c.classList.toggle("animate","true"===s.getItem("light"));const m=s.getItem("font");i.setProperty("--global-font","default"===m?"-apple-system":m);const d=btf.map.get(s.getItem("themeColor")),g=d.slice(3,-1);d&&(e=>{for(const[t,o]of Object.entries(e))i.setProperty(t,o)})({"--theme-color":d,"--text-bg-hover":`rgba${g}, 0.7)`,"--high-trans-color":`rgba${g}, 0.5)`,"--hh-trans-color":`rgba${g}, 0.1)`});const u="1"===s.getItem("asidePos");i.setProperty("--first-child-order",u?"0":"2"),i.setProperty("--recent-post-item-margin",u?"0 0 0 15px":"0 15px 0 0"),i.setProperty("--recent-post-item-margin-other",u?"0 0 0 15px":"0 15px 0 0");const b=s.getItem("transNum");i.setProperty("--trans-light",`rgba(253, 253, 253, ${b}%)`),i.setProperty("--trans-dark",`rgba(20, 24, 30, ${b}%)`),i.setProperty("--trans-comment-dark",`rgba(28, 32, 40, ${b}%)`);const p=s.getItem("blurRad");i.setProperty("--blur-num",`blur(${p}px) saturate(120%) contrast(105%)`);const f=s.getItem("blogbg"),y={"--default-bg":"url(https://img.aimiliy.top/wallpaper?type=pc)","--darkmode-bg":"url(https://img.aimiliy.top/wallpaper?type=pc)","--mobileday-bg":"url(https://cdn.aimiliy.top/backImg/418aa5a692048078aec56e073ed15e8849ff99a012daa8-4Bc9wf.webp)","--mobilenight-bg":"url(https://cdn.aimiliy.top/backImg/20191012131221_mTGle.webp)"},h=Object.keys(y);if("default"===f)for(const e of h)i.setProperty(e,y[e]);else if(f){const e=f.startsWith("linear-gradient"),t=/^#([0-9a-fA-F]{3}|[0-9a-fA-F]{6})$/.test(f);for(const o of h)e||t?i.setProperty(o,f):i.setProperty(o,`url(${f})`)}i.setProperty("--menu-shadow","true"===s.getItem("light")?"0 0 1px var(--theme-color)":"none")})()</script><script defer data-pjax src="/lib/hbe.js?v=1.8.39"></script><link href="/css/hbe.style.css?v=1.8.39" rel="stylesheet"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="MuXiaoChen🍊" type="application/atom+xml"></head><body data-type=""><div id="loading-box" onclick='document.getElementById("loading-box").classList.add("loaded")'><div class="mbg-top"></div><img class="mbg-loading-img nolazyload" alt="加载头像" src="https://cdn.aimiliy.top/avatar/202504256.webp"><div class="mbg-bottom"></div></div><div id="web_bg"></div><div id="an_music_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/202504256.webp" onerror='onerror=null,src="/assets/r1.webp"' alt="avatar"></div><div class="author-info__name">MuXiaoChen🍊</div><div class="author-info__description">No pains, no gains. 🌱🔥🚀</div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">39</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn-bar" target="_blank" rel="noopener" href="https://github.com/TXM983" title="前往作者的Github"><i class="fab fa-github" style="margin-left:40px"></i><span>Follow Me</span><i class="faa-passing animated" style="padding-left:20px;display:inline-block;vertical-align:middle"><svg class="icon" style="height:28px;width:28px;fill:currentColor;position:relative;top:5px"><use xlink:href="#icon-xiaoqiche"></use></svg></i></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="/assets/QRCode.webp" target="_blank" title="微信"><svg class="social_icon faa-tada" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://res.abeim.cn/api/qq/?qq=1554267532" target="_blank" title="QQ"><svg class="social_icon faa-tada" aria-hidden="true"><use xlink:href="#icon-QQ"></use></svg></a><a class="social-icon faa-parent animated-hover" href="mailto:1554267532@qq.com" target="_blank" title="QQ邮箱"><svg class="social_icon faa-tada" aria-hidden="true"><use xlink:href="#icon-youxiang"></use></svg></a><a class="social-icon faa-parent animated-hover" href="/atom.xml" target="_blank" title="RSS"><svg class="social_icon faa-tada" aria-hidden="true"><use xlink:href="#icon-RSS"></use></svg></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-home-19"></use></svg> <span class="menu_word" style="font-size:17px">导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-home"></use></svg> <span class="menu_word" style="font-size:17px">首页</span></a></li><li><a class="site-page child" href="/archives/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-guidang1"></use></svg> <span class="menu_word" style="font-size:17px">归档</span></a></li><li><a class="site-page child" href="/tags/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg> <span class="menu_word" style="font-size:17px">标签</span></a></li><li><a class="site-page child" href="/categories/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg> <span class="menu_word" style="font-size:17px">分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-kafei"></use></svg> <span class="menu_word" style="font-size:17px">休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/life/music/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg> <span class="menu_word" style="font-size:17px">音乐</span></a></li><li><a class="site-page child" href="/life/movies/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-dianying1"></use></svg> <span class="menu_word" style="font-size:17px">影院</span></a></li><li><a class="site-page child" href="/life/games/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-youxishoubing"></use></svg> <span class="menu_word" style="font-size:17px">游戏</span></a></li><li><a class="site-page child" href="/life/bangumi/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-wodezhuifan"></use></svg> <span class="menu_word" style="font-size:17px">追番</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-liwu-18"></use></svg> <span class="menu_word" style="font-size:17px">百宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/box/gallery/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-tubiaozhizuomoban"></use></svg> <span class="menu_word" style="font-size:17px">画廊</span></a></li><li><a class="site-page child" href="/box/animation/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-nvwumao"></use></svg> <span class="menu_word" style="font-size:17px">动画</span></a></li><li><a class="site-page child" href="/box/nav/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-zhifengche"></use></svg> <span class="menu_word" style="font-size:17px">收藏</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-shejiaoxinxi-18"></use></svg> <span class="menu_word" style="font-size:17px">社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/social/fcircle/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-pengyouquan"></use></svg> <span class="menu_word" style="font-size:17px">朋友圈</span></a></li><li><a class="site-page child" href="/comments/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-liuyan"></use></svg> <span class="menu_word" style="font-size:17px">留言板</span></a></li><li><a class="site-page child" href="/social/link/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-lianjie"></use></svg> <span class="menu_word" style="font-size:17px">友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-wangye-12"></use></svg> <span class="menu_word" style="font-size:17px">网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/site/census/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon--tongjibiao"></use></svg> <span class="menu_word" style="font-size:17px">网站统计</span></a></li><li><a class="site-page child" href="/site/echarts/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-shujutongji1"></use></svg> <span class="menu_word" style="font-size:17px">文章统计</span></a></li><li><a class="site-page child" href="/site/time/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-xianxingshalou"></use></svg> <span class="menu_word" style="font-size:17px">流光拾遗</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-maoliang"></use></svg> <span class="menu_word" style="font-size:17px">个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/personal/bb/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-qunliaotian"></use></svg> <span class="menu_word" style="font-size:17px">生活点滴</span></a></li><li><a class="site-page child" href="/personal/secret/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-youhua-fengshu"></use></svg> <span class="menu_word" style="font-size:17px">浮光小筑</span></a></li><li><a class="site-page child" href="/personal/about/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-paperplane"></use></svg> <span class="menu_word" style="font-size:17px">自述与我</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">MuXiaoChen🍊</a></span><div class="menus_items"><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-home-19"></use></svg> <span class="menu_word" style="font-size:17px">导航</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-home"></use></svg> <span class="menu_word" style="font-size:17px">首页</span></a></li><li><a class="site-page child" href="/archives/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-guidang1"></use></svg> <span class="menu_word" style="font-size:17px">归档</span></a></li><li><a class="site-page child" href="/tags/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg> <span class="menu_word" style="font-size:17px">标签</span></a></li><li><a class="site-page child" href="/categories/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg> <span class="menu_word" style="font-size:17px">分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-kafei"></use></svg> <span class="menu_word" style="font-size:17px">休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/life/music/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg> <span class="menu_word" style="font-size:17px">音乐</span></a></li><li><a class="site-page child" href="/life/movies/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-dianying1"></use></svg> <span class="menu_word" style="font-size:17px">影院</span></a></li><li><a class="site-page child" href="/life/games/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-youxishoubing"></use></svg> <span class="menu_word" style="font-size:17px">游戏</span></a></li><li><a class="site-page child" href="/life/bangumi/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-wodezhuifan"></use></svg> <span class="menu_word" style="font-size:17px">追番</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-liwu-18"></use></svg> <span class="menu_word" style="font-size:17px">百宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/box/gallery/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-tubiaozhizuomoban"></use></svg> <span class="menu_word" style="font-size:17px">画廊</span></a></li><li><a class="site-page child" href="/box/animation/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-nvwumao"></use></svg> <span class="menu_word" style="font-size:17px">动画</span></a></li><li><a class="site-page child" href="/box/nav/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-zhifengche"></use></svg> <span class="menu_word" style="font-size:17px">收藏</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-shejiaoxinxi-18"></use></svg> <span class="menu_word" style="font-size:17px">社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/social/fcircle/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-pengyouquan"></use></svg> <span class="menu_word" style="font-size:17px">朋友圈</span></a></li><li><a class="site-page child" href="/comments/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-liuyan"></use></svg> <span class="menu_word" style="font-size:17px">留言板</span></a></li><li><a class="site-page child" href="/social/link/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-lianjie"></use></svg> <span class="menu_word" style="font-size:17px">友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-wangye-12"></use></svg> <span class="menu_word" style="font-size:17px">网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/site/census/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon--tongjibiao"></use></svg> <span class="menu_word" style="font-size:17px">网站统计</span></a></li><li><a class="site-page child" href="/site/echarts/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-shujutongji1"></use></svg> <span class="menu_word" style="font-size:17px">文章统计</span></a></li><li><a class="site-page child" href="/site/time/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-xianxingshalou"></use></svg> <span class="menu_word" style="font-size:17px">流光拾遗</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-maoliang"></use></svg> <span class="menu_word" style="font-size:17px">个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/personal/bb/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-qunliaotian"></use></svg> <span class="menu_word" style="font-size:17px">生活点滴</span></a></li><li><a class="site-page child" href="/personal/secret/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-youhua-fengshu"></use></svg> <span class="menu_word" style="font-size:17px">浮光小筑</span></a></li><li><a class="site-page child" href="/personal/about/"><svg class="menus_svg_header" aria-hidden="true"><use xlink:href="#icon-paperplane"></use></svg> <span class="menu_word" style="font-size:17px">自述与我</span></a></li></ul></div></div><div id="name-container-mask"><div class="visible" id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></div></div><div id="nav-right"><div id="search-button"><span class="search site-page" title="检索站内任何你想要的信息"><svg class="svg-header" aria-hidden="true"><use xlink:href="#icon-sousuo5"></use></svg></span></div><div id="beautify-button"><span class="site-page" onclick="toggleWinbox()" title="美化设置-自定义你的风格"><svg class="svg-header" aria-hidden="true"><use xlink:href="#icon-meihua"></use></svg></span></div><div id="tenYears"><a class="site-page" target="_blank" rel="noopener" href="https://foreverblog.cn/go.html" title="穿梭虫洞-十年之约"><svg class="svg-header" aria-hidden="true"><use xlink:href="#icon-huochezhan"></use></svg></a></div><div id="toggle-menu"><span class="site-page"><a><i class="fas fa-bars fa-fw" style="color:#3e86f1"></i></a></span></div></div></nav><div id="post-info"><h1 class="post-title">Pytorch基础知识（一）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于</span> <time class="post-meta-date-created" datetime="2024-07-02T08:39:08.000Z" title="发表于 2024-07-02 16:39:08">2024-07-02</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-29T15:23:47.806Z" title="更新于 2025-05-29 23:23:47">2025-05-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/">教程笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">2580</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Pytorch基础知识（一）"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s58 18 88 18 58-18 88-18 58 18 88 18v44h-352Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div class="post-outdate-notice" id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2025-05-29 23:23:47&quot;}" hidden></div><h1 id="pytorch环境部署"><a href="#pytorch环境部署" class="headerlink" title="pytorch环境部署"></a>pytorch环境部署</h1><h2 id="安装conda"><a href="#安装conda" class="headerlink" title="安装conda"></a>安装conda</h2><p>conda 是一个开源的软件包管理系统和环境管理软件，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。conda 是为Python程序创建的，类似于 Linux、MacOS、Windows，也可以打包和分发其他软件。<br><strong>注意：必须在 cmd 里面才可以，在 powershell 里面输入命令有些是无效的</strong></p><h2 id="创建Python环境"><a href="#创建Python环境" class="headerlink" title="创建Python环境"></a>创建Python环境</h2><p>创建环境<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n name python=3.8  ##示例，实际根据需求选择Python版本以及设置环境名称</span><br></pre></td></tr></table></figure><br>激活环境<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate name</span><br></pre></td></tr></table></figure><br>退出环境<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deavtivate</span><br></pre></td></tr></table></figure><br>查看环境下包的信息<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip list # 列出pip环境里的所有包</span><br><span class="line">conda list # 列出conda环境里的所有包</span><br></pre></td></tr></table></figure><p></p><h2 id="安装NVIDIA-CUDA以及CUDNN（若没有GPU可以跳过本步骤）"><a href="#安装NVIDIA-CUDA以及CUDNN（若没有GPU可以跳过本步骤）" class="headerlink" title="安装NVIDIA CUDA以及CUDNN（若没有GPU可以跳过本步骤）"></a>安装NVIDIA CUDA以及CUDNN（若没有GPU可以跳过本步骤）</h2><h3 id="查看本机GPU信息"><a href="#查看本机GPU信息" class="headerlink" title="查看本机GPU信息"></a>查看本机GPU信息</h3><p>在CMD控制台中输入以下命令就可以查看本机GPU型号以及其适配CUDA型号信息<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi # 查看本机GPU型号以及其适配CUDA的信息</span><br></pre></td></tr></table></figure><p></p><h3 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h3><ol><li>下载CUDA安装包，下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a><ul><li>选择Windows或者Linux，选择对应版本的CUDA安装包</li></ul></li><li>安装CUDA安装包<ul><li>默认安装即可，如果出现错误，可以参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_53762670/article/details/131845364">https://blog.csdn.net/weixin_53762670/article/details/131845364</a></li></ul></li><li><p>验证CUDA安装是否成功</p><ul><li>打开cmd，输入以下命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>如果出现以下信息，则说明安装成功<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2021 NVIDIA Corporation</span><br><span class="line">Built on Wed_Jun__2_19:15:15_Pacific_Daylight_Time_2021</span><br><span class="line">Cuda compilation tools, release 11.5, V11.5.119</span><br></pre></td></tr></table></figure></li></ul></li><li><p>安装CUDNN</p><ul><li>下载CUDNN安装包，下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></li><li>选择对应CUDA版本的CUDNN安装包</li><li>将下载后的压缩包解压到CUDA安装的根目录下，例如：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.5</li></ul></li><li>验证CUDNN安装是否成功<ul><li>进入到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7\extras\demo_suite 目录下，在上方文件路径中输入CMD，<br>然后回车，进入到该目录命令窗口下，首先输入bandwidth.exe，如果出现以下信息，则说明安装成功</li><li><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/articlePic/img.png" alt="img.png"></li><li>然后在输入deviceQuery.exe，如果出现以下信息，则说明安装成功</li><li><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/articlePic/img_1.png" alt="img_1.png"></li></ul></li></ol><h2 id="安装Pytorch"><a href="#安装Pytorch" class="headerlink" title="安装Pytorch"></a>安装Pytorch</h2><h3 id="安装Pytorch相关包"><a href="#安装Pytorch相关包" class="headerlink" title="安装Pytorch相关包"></a>安装Pytorch相关包</h3><p>输入以下命令安装Pytorch<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia ## 注意pytorch-cuda版本替换为自己实际的CUDA版本</span><br></pre></td></tr></table></figure><p></p><h3 id="验证Pytorch安装是否成功"><a href="#验证Pytorch安装是否成功" class="headerlink" title="验证Pytorch安装是否成功"></a>验证Pytorch安装是否成功</h3><ul><li>打开cmd，输入以下命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda activate name # 激活对应环境</span><br><span class="line">python</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; import torch</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; torch.cuda.is_available()</span></span><br></pre></td></tr></table></figure></li><li>如果出现以下信息，则说明安装成功，可以使用GPU进行训练<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; import torch</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; torch.cuda.is_available()</span></span><br><span class="line">True</span><br></pre></td></tr></table></figure><h1 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h1><h2 id="数据集的加载"><a href="#数据集的加载" class="headerlink" title="数据集的加载"></a>数据集的加载</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torchvision import transforms</span><br><span class="line">trans = transforms.Compose([</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;,train=True,transform=trans,download=True)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;,train=False,transform=trans,download=True)</span><br><span class="line">img,target = test_set[0]</span><br><span class="line">print(img) </span><br><span class="line">print(target)</span><br><span class="line">print(test_set.classes[target])</span><br></pre></td></tr></table></figure>Dataset介绍：<ul><li>Dataset 是一个抽象类，不能直接使用，需要继承 Dataset 类，然后重写 <strong>getitem</strong> 和 <strong>len</strong> 方法，这两个方法都是抽象方法，必须实现。</li><li><strong>getitem</strong> 方法用于获取数据集的某一个样本，返回一个样本。</li><li><strong>len</strong> 方法用于获取数据集的长度，返回一个整数。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.data import Dataset</span><br><span class="line">import cv2</span><br><span class="line">from PIL import Image</span><br><span class="line">import os</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">help</span>(Dataset)</span></span><br><span class="line">class mydata(Dataset):</span><br><span class="line">def __init__(self,root_dir,label_dir):</span><br><span class="line">self.root_dir = root_dir</span><br><span class="line">self.label_dir = label_dir</span><br><span class="line">self.path = os.path.join(self.root_dir,self.label_dir)</span><br><span class="line">self.img_path = os.listdir(self.path)</span><br><span class="line">   def __getitem__(self, idx):</span><br><span class="line">       img_name = self.img_path[idx]</span><br><span class="line">       img_item_path = os.path.join(self.root_dir,self.label_dir,self.img_path)</span><br><span class="line">       img = Image.open(img_item_path)</span><br><span class="line">       label = self.label_dir</span><br><span class="line">       return img,label</span><br><span class="line">   def __len__(self):</span><br><span class="line">       return len(self.img_path)</span><br><span class="line">ants_dataset = mydata(root_dir,label_dir)</span><br><span class="line">img, label = ants_dataset[0]</span><br><span class="line">img.show()</span><br><span class="line">bees_dataset = mydata(root_dir,label_dir)</span><br><span class="line">all_train = ants_dataset+bees_dataset //拼接数据集</span><br><span class="line">len(all_train)</span><br></pre></td></tr></table></figure>DataLoader介绍：</li><li>DataLoader 是一个迭代器，用于加载数据集。 可以通过 DataLoader 的参数设置，如 batch_size、shuffle、num_workers 等，来控制加载数据的方式。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torchvision import transforms</span><br><span class="line">from torch.utils.data.dataloader import DataLoader</span><br><span class="line">trans = transforms.Compose([</span><br><span class="line">transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;,train=True,transform=trans,download=True)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;,train=False,transform=trans,download=True)</span><br><span class="line">print(type(test_set))</span><br><span class="line">loader = DataLoader(dataset=test_set,batch_size=64,shuffle=True,num_workers=0,drop_last=False)</span><br><span class="line"></span><br><span class="line">img,target = test_set[0]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">torch.Size([3, 32, 32])</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3</span></span><br><span class="line">print(img.shape)</span><br><span class="line">print(target)</span><br><span class="line"></span><br><span class="line">for data in loader:</span><br><span class="line">imgs,targets =data</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">torch.Size([64, 3, 32, 32])</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">torch.Size([64])</span></span><br><span class="line">print(imgs.shape)</span><br><span class="line">print(targets.shape)</span><br><span class="line">break</span><br></pre></td></tr></table></figure><h1 id="搭建网络"><a href="#搭建网络" class="headerlink" title="搭建网络"></a>搭建网络</h1>nn.Module介绍：</li><li>nn.Module 是一个抽象类，不能直接使用，需要继承 nn.Module 类，然后重写 forward 方法，这个方法就是网络结构。</li><li>forward 方法用于定义网络结构，返回一个张量。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from torch import nn </span><br><span class="line">import torch</span><br><span class="line">class mymodel(nn.Module):</span><br><span class="line">def __init__(self) :</span><br><span class="line">super(mymodel,self).__init__()</span><br><span class="line"></span><br><span class="line"> def forward(self,x):</span><br><span class="line">     y = x+1</span><br><span class="line">     return y</span><br><span class="line"></span><br><span class="line">a = mymodel()</span><br><span class="line">x = torch.tensor([10,20,30])</span><br><span class="line">print(a(x))</span><br></pre></td></tr></table></figure>搭建网络：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torchvision</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line">from torch.nn import MaxPool2d</span><br><span class="line">from torch.nn import ReLU</span><br><span class="line">from torch.nn import Flatten</span><br><span class="line">from torch.nn import Linear</span><br><span class="line">from torch.nn import Sigmoid</span><br><span class="line">from torch.nn import Sequential</span><br><span class="line">from torch.utils.data.dataloader import DataLoader</span><br><span class="line">from tensorboardX import SummaryWriter</span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./dataset&quot;,train=False,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">download=True)</span><br><span class="line">dataloader  = DataLoader(dataset,batch_size=64)</span><br><span class="line"></span><br><span class="line">class mod(nn.Module):</span><br><span class="line">def __init__(self):</span><br><span class="line">super(mod,self).__init__()</span><br><span class="line">self.conv1 = Conv2d(3,32,5,stride=1,padding=2)</span><br><span class="line">self.max_pool2d = MaxPool2d(2)</span><br><span class="line">self.conv2 = Conv2d(32,32,5,padding=2)</span><br><span class="line">self.max_pool2d2 = MaxPool2d(2)</span><br><span class="line">self.conv3 = Conv2d(32,64,5,padding=2)</span><br><span class="line">self.max_pool2d3 = MaxPool2d(2)</span><br><span class="line">self.flatten = Flatten()</span><br><span class="line">self.Linear = Linear(1024,64)</span><br><span class="line">self.Linear2 = Linear(64,10)</span><br><span class="line"></span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(3,32,5,stride=1,padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32,32,5,padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32,64,5,padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(1024,64),</span><br><span class="line">            Linear(64,10),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        # x=self.conv1(x)</span><br><span class="line">        # x=self.max_pool2d(x)</span><br><span class="line">        # x=self.conv2(x)</span><br><span class="line">        # x=self.max_pool2d2(x)</span><br><span class="line">        # x=self.conv3(x)</span><br><span class="line">        # x=self.max_pool2d3(x)</span><br><span class="line">        # x=self.flatten(x)</span><br><span class="line">        # x=self.Linear(x)</span><br><span class="line">        # x=self.Linear2(x)</span><br><span class="line">        x = self.model1(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">modshi = mod()</span><br><span class="line">print(modshi)</span><br><span class="line"></span><br><span class="line">x = torch.ones((64,3,32,32))</span><br><span class="line">out = modshi(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for data in dataloader:</span><br><span class="line">imgs,targers = data</span><br><span class="line">out = modshi(imgs)</span><br><span class="line">print(out.shape)</span><br><span class="line">break</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可视化网络</span></span><br><span class="line">writer = SummaryWriter(&quot;logs&quot;)</span><br><span class="line">writer.add_graph(modshi,x)</span><br><span class="line">writer.close()</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mod(</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (max_pool2d2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (max_pool2d3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (flatten): Flatten(start_dim=1, end_dim=-1)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (Linear): Linear(in_features=1024, out_features=64, bias=True)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (Linear2): Linear(in_features=64, out_features=10, bias=True)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (model1): Sequential(</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (6): Flatten(start_dim=1, end_dim=-1)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (7): Linear(in_features=1024, out_features=64, bias=True)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">    (8): Linear(in_features=64, out_features=10, bias=True)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  )</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">torch.Size([64, 10])</span> </span><br></pre></td></tr></table></figure>损失函数：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.nn import L1Loss</span><br><span class="line">from torch.nn import MSELoss</span><br><span class="line">from torch.nn import CrossEntropyLoss</span><br><span class="line">x = torch.tensor([1,2,3],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([1,2,5],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">x = torch.reshape(x,(1,1,1,3))</span><br><span class="line">y = torch.reshape(y,(1,1,1,3))</span><br><span class="line"></span><br><span class="line">loss = L1Loss(reduce=&#x27;sum&#x27;)</span><br><span class="line">result = loss(x,y)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line">loss = MSELoss()</span><br><span class="line">result = loss(x,y)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([0.1,0.2,0.3])</span><br><span class="line">y = torch.tensor([1])</span><br><span class="line">x = torch.reshape(x,(1,3))</span><br><span class="line">loss = CrossEntropyLoss()</span><br><span class="line">result = loss(x,y)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>优化器：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torchvision</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line">from torch.nn import MaxPool2d</span><br><span class="line">from torch.nn import ReLU</span><br><span class="line">from torch.nn import Flatten</span><br><span class="line">from torch.nn import Linear</span><br><span class="line">from torch.nn import Sigmoid</span><br><span class="line">from torch.nn import Sequential</span><br><span class="line">from torch.utils.data.dataloader import DataLoader</span><br><span class="line">from torch.nn import CrossEntropyLoss</span><br><span class="line">from torch.optim import SGD</span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./dataset&quot;,train=False,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">download=True)</span><br><span class="line">dataloader  = DataLoader(dataset,batch_size=64)</span><br><span class="line"></span><br><span class="line">class mod(nn.Module):</span><br><span class="line">def __init__(self):</span><br><span class="line">super(mod,self).__init__()</span><br><span class="line">self.model1 = Sequential(</span><br><span class="line">Conv2d(3,32,5,stride=1,padding=2),</span><br><span class="line">MaxPool2d(2),</span><br><span class="line">Conv2d(32,32,5,padding=2),</span><br><span class="line">MaxPool2d(2),</span><br><span class="line">Conv2d(32,64,5,padding=2),</span><br><span class="line">MaxPool2d(2),</span><br><span class="line">Flatten(),</span><br><span class="line">Linear(1024,64),</span><br><span class="line">Linear(64,10),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">modshi = mod()</span><br><span class="line">loss = CrossEntropyLoss()</span><br><span class="line">optim = SGD(modshi.parameters(),lr=0.01)</span><br><span class="line"></span><br><span class="line">for epoch in range(20):</span><br><span class="line">runing_loss = 0.0</span><br><span class="line">for data in dataloader:</span><br><span class="line">imgs,targers = data</span><br><span class="line">out = modshi(imgs)</span><br><span class="line">loss1 = loss(out,targers)</span><br><span class="line">optim.zero_grad()</span><br><span class="line">loss1.backward()</span><br><span class="line">optim.step()</span><br><span class="line">runing_loss = runing_loss+loss1</span><br><span class="line">print(runing_loss)</span><br></pre></td></tr></table></figure>GPU的使用：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fff = model.cuda()</span><br><span class="line">loss_fn = loss.cuda()</span><br><span class="line">imgs = imgs.cuda()</span><br><span class="line">targets = targets.cuda()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&quot;cuda&quot;)</span><br><span class="line">model = model.to(device)</span><br><span class="line">imgs = imgs.to(device)</span><br></pre></td></tr></table></figure>现有模型使用：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vgg16_true = torchvision.models.vgg16(pretrained=True)</span><br><span class="line">vgg16_false = torchvision.models.vgg16(pretrained=False)</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./dataset&quot;,train=False,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">download=True)</span><br><span class="line">dataloader  = DataLoader(dataset,batch_size=64)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在最后一层加先行层从1000-》10</span></span><br><span class="line">vgg16_true.add_module(&#x27;add&#x27;,nn.Linear(1000,10))</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改vgg最后一层</span></span><br><span class="line">vgg16_false.classifier[6] = nn.Linear(4096,10)</span><br></pre></td></tr></table></figure>保存读取网络：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=True)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存1,模型结构和参数,需要模型定义的代码</span></span><br><span class="line">torch.save(vgg16,&#x27;vgg16.pth&#x27;)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载1</span></span><br><span class="line">model = torch.load(&#x27;vgg16.pth&#x27;)</span><br><span class="line">print(model)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存2，保存参数字典形式</span></span><br><span class="line">torch.save(vgg16.state_dict(),&quot;vgg.pth&quot;)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载2</span></span><br><span class="line">model = torchvision.models.vgg16()</span><br><span class="line">model.load_state_dict(torch.load(&#x27;vgg.pth&#x27;))</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="完整的训练验证流程"><a href="#完整的训练验证流程" class="headerlink" title="完整的训练验证流程"></a>完整的训练验证流程</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">model.py</span></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class fff(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(fff, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(3, 32, 5, stride=1, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 32, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 64, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(1024, 64),</span><br><span class="line">            Linear(64, 10),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    model = fff()</span><br><span class="line">    x = torch.ones(64,3,32,32)</span><br><span class="line">    y = model(x)</span><br><span class="line">    print(y.shape)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">main.py</span></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import torchvision</span><br><span class="line">from model import fff</span><br><span class="line">from tensorboardX import SummaryWriter</span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=&#x27;dataset&#x27;, train=True, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download=True)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=&#x27;dataset&#x27;, train=False, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download=True)</span><br><span class="line"></span><br><span class="line">print(&quot;训练数据集长度为&#123;&#125;&quot;.format(len(train_data)))</span><br><span class="line">print(&quot;测试数据集长度为&#123;&#125;&quot;.format(len(test_data)))</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=64)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=64)</span><br><span class="line"></span><br><span class="line">model = fff()</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">learn = 1e-2</span><br><span class="line">optim = torch.optim.SGD(model.parameters(),lr=learn)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">记录训练次数</span></span><br><span class="line">total_train_step = 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">记录测试次数</span></span><br><span class="line">total_test_step = 0</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">训练轮数</span></span><br><span class="line">epoch = 10</span><br><span class="line">writer = SummaryWriter(&quot;logs&quot;)</span><br><span class="line"></span><br><span class="line">for i in range(epoch):</span><br><span class="line">    model.train()</span><br><span class="line">    print(&#x27;-------------------------&#123;&#125;轮开始-------------------&#x27;.format(i))</span><br><span class="line">    for data in train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        y = model(imgs)</span><br><span class="line">        loss1 = loss(y, targets)</span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss1.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        total_train_step+=1</span><br><span class="line">        if total_train_step % 300 == 0:</span><br><span class="line">            print(&quot;第&#123;&#125;次,损失为&#123;&#125;&quot;.format(total_train_step, loss1.item()))</span><br><span class="line">            writer.add_scalar(&quot;train_loss&quot;,loss1.item(),total_train_step)</span><br><span class="line">    model.eval()</span><br><span class="line">    total_test_loss = 0</span><br><span class="line">    total_accuracy = 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for data in test_dataloader:</span><br><span class="line">            imgs ,targets = data</span><br><span class="line">            y = model(imgs)</span><br><span class="line">            loss1 = loss(y,targets)</span><br><span class="line">            total_test_loss +=loss1</span><br><span class="line">            accuracy = (y.argmax(1)==targets).sum()</span><br><span class="line">            total_accuracy+=accuracy</span><br><span class="line">    print(&quot;整体测试集上loss&#123;&#125;&quot;.format(total_test_loss))</span><br><span class="line">    print(&quot;整体测试集上accuracy&#123;&#125;&quot;.format(total_accuracy/len(test_data)))</span><br><span class="line">    writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(&quot;test_accuracy&quot;, total_accuracy/len(test_data), total_test_step)</span><br><span class="line">    total_test_step += 1</span><br><span class="line"></span><br><span class="line">    torch.save(model,&quot;cif&#123;&#125;.pth&quot;.format(i))</span><br><span class="line">    print(&quot;save over&quot;)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">test.py</span></span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line">import torchvision</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">img_path = &quot;image/下载.jpeg&quot;</span><br><span class="line">img = Image.open(img_path)</span><br><span class="line">trans = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.Resize((32, 32)),</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line">img = trans(img)</span><br><span class="line">img = torch.reshape(img, (1, 3, 32, 32))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class fff(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(fff, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(3, 32, 5, stride=1, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 32, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 64, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(64*4*4, 64),</span><br><span class="line">            Linear(64, 10),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line"></span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">device = torch.device(&quot;mps&quot;)</span><br><span class="line">model = torch.load(&quot;./cif9.pth&quot;).to(device)</span><br><span class="line">model.eval()</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    img = img.to(device)</span><br><span class="line">    y = model(img)</span><br><span class="line">    y = y.argmax(1)</span><br><span class="line">    print(y)</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>Pytorch基础知识（一）</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://miraii.cn/posts/5a986f0/">https://miraii.cn/posts/5a986f0/</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>MuXiaoChen🍊</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-07-02</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2025-05-29</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/"><div class="tags-punctuation"><svg class="faa-tada svg_tag icon" aria-hidden="true"><use xlink:href="#icon-wenzhangbiaoqian-copy"></use></svg></div>Pytorch</a><a class="post-meta__tags" href="/tags/Machine-Learning/"><div class="tags-punctuation"><svg class="faa-tada svg_tag icon" aria-hidden="true"><use xlink:href="#icon-wenzhangbiaoqian-copy"></use></svg></div>Machine Learning</a><a class="post-meta__tags" href="/tags/Deep-Learning/"><div class="tags-punctuation"><svg class="faa-tada svg_tag icon" aria-hidden="true"><use xlink:href="#icon-wenzhangbiaoqian-copy"></use></svg></div>Deep Learning</a></div></div><link rel="stylesheet" href="/css/coin.css?v=1.8.39" media="defer" onload='this.media="all"'><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.aimiliy.top/reward/wechat.webp" target="_blank"><img class="post-qr-code-img" src="https://cdn.aimiliy.top/reward/wechat.webp" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.aimiliy.top/reward/alipay.webp" target="_blank"><img class="post-qr-code-img" src="https://cdn.aimiliy.top/reward/alipay.webp" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://cdn.aimiliy.top/reward/aowu.m4a"></audio><script defer src="/js/coin.js?v=1.8.39"></script><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/bc5092e1/" title="艾尔登法环DLC - 黄金树之影"><img class="cover nolazyload" src="https://cdn.aimiliy.top/articleBackground/article5.webp" onerror='onerror=null,src="/assets/r2.webp"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">艾尔登法环DLC - 黄金树之影</div></div><div class="info-2"><div class="info-item-1">DLC - 黄金树之影</div></div></div></a><a class="pagination-related" href="/posts/414a7aa/" title="Pytorch基础知识（二）"><img class="cover nolazyload" src="https://cdn.aimiliy.top/articleBackground/article7.webp" onerror='onerror=null,src="/assets/r2.webp"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Pytorch基础知识（二）</div></div><div class="info-2"><div class="info-item-1">本文主要介绍有关Pytorch的基础知识（二）</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/414a7aa/" title="Pytorch基础知识（二）"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/articleBackground/article7.webp" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="fas fa-history fa-fw"></i> 2025-05-29</div><div class="info-item-2">Pytorch基础知识（二）</div></div><div class="info-2"><div class="info-item-1">本文主要介绍有关Pytorch的基础知识（二）</div></div></div></a></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:700">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2"><span class="toc-number">1.</span> <span class="toc-text">pytorch环境部署</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85conda"><span class="toc-number">1.1.</span> <span class="toc-text">安装conda</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAPython%E7%8E%AF%E5%A2%83"><span class="toc-number">1.2.</span> <span class="toc-text">创建Python环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85NVIDIA-CUDA%E4%BB%A5%E5%8F%8ACUDNN%EF%BC%88%E8%8B%A5%E6%B2%A1%E6%9C%89GPU%E5%8F%AF%E4%BB%A5%E8%B7%B3%E8%BF%87%E6%9C%AC%E6%AD%A5%E9%AA%A4%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">安装NVIDIA CUDA以及CUDNN（若没有GPU可以跳过本步骤）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%9C%AC%E6%9C%BAGPU%E4%BF%A1%E6%81%AF"><span class="toc-number">1.3.1.</span> <span class="toc-text">查看本机GPU信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85CUDA"><span class="toc-number">1.3.2.</span> <span class="toc-text">安装CUDA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Pytorch"><span class="toc-number">1.4.</span> <span class="toc-text">安装Pytorch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85Pytorch%E7%9B%B8%E5%85%B3%E5%8C%85"><span class="toc-number">1.4.1.</span> <span class="toc-text">安装Pytorch相关包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81Pytorch%E5%AE%89%E8%A3%85%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F"><span class="toc-number">1.4.2.</span> <span class="toc-text">验证Pytorch安装是否成功</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">处理数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%8A%A0%E8%BD%BD"><span class="toc-number">2.1.</span> <span class="toc-text">数据集的加载</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">3.</span> <span class="toc-text">搭建网络</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E9%AA%8C%E8%AF%81%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">完整的训练验证流程</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-first"></div><div id="footer-wrap"><div class="global-footer"><div class="footer-container"><section class="footer-section motto-container"><h3 class="section-heading">📜 生活箴言</h3><p class="motto-content">人生如逆旅，我亦是行人。保持从容心态，笑看云卷云舒。 不必追赶时间，学会驻足欣赏，心若向阳，处处皆暖阳。</p><a class="nav-item" target="_blank" rel="noopener" href="https://stellarium.org/">探索星空之旅 →</a></section><section class="footer-section nav-container"><h3 class="section-heading">🗺️ 网站地图</h3><nav class="nav-grid"><a class="nav-item" href="/">返回主页</a><a class="nav-item" href="/box/nav/">网址导航</a><a class="nav-item" href="/social/link/">我的朋友</a><a class="nav-item" href="/comments/">留点什么</a><a class="nav-item" href="/personal/about/">关于作者</a><a class="nav-item" href="/archives/">文章归档</a><a class="nav-item" href="/categories/">文章分类</a><a class="nav-item" href="/tags/">文章标签</a><a class="nav-item" href="/box/gallery/">我的画廊</a><a class="nav-item" href="/personal/bb/">日常分享</a><a class="nav-item" href="/site/time/">建设进程</a><a class="nav-item" href="/site/census/">网站统计</a></nav></section><section class="footer-section partner-container"><h3 class="section-heading">⌛ 友情链接</h3><div class="partner-grid"><a class="partner-link" target="_blank" rel="noopener" href="https://poetize.cn/" title="POETIZE"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/poetize.cn.webp" alt="POETIZE"></a><a class="partner-link" target="_blank" rel="noopener" href="https://www.mxin.moe" title="铭心"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/www.mxin.moe.webp" alt="铭心"></a><a class="partner-link" href="https://miraii.cn/" title="MuXiaoChen🍊"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/202504256.webp" alt="MuXiaoChen🍊"></a><a class="partner-link" target="_blank" rel="noopener" href="https://starsei.com/" title="猫不吃鱼"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/starsei.com.ico" alt="猫不吃鱼"></a><a class="partner-link" target="_blank" rel="noopener" href="https://www.hoshiroko.com" title="薄荷の小屋"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/www.hoshiroko.com.webp" alt="薄荷の小屋"></a><a class="partner-link" target="_blank" rel="noopener" href="https://blog.ltya.top" title="岚天小窝"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/blog.ltya.top.webp" alt="岚天小窝"></a><a class="partner-link" target="_blank" rel="noopener" href="https://jipa.moe" title="JIPA233の小窝"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/jipa.moe.webp" alt="JIPA233の小窝"></a><a class="partner-link" target="_blank" rel="noopener" href="https://blog.iamsjy.com/" title="Tony’s Blog"><img class="partner-image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.aimiliy.top/avatar/blog.iamsjy.com.webp" alt="Tony’s Blog"></a></div></section></div></div></div><div id="footer-wrap-bottom"><div id="footer-bottom"><div class="footer-bottom-content"><div class="footer-bottom-left"><span class="copyright"><b>&copy;2023-2025</b><b>&nbsp;&nbsp;By</b><b>&nbsp;MuXiaoChen🍊</b></span><div><a class="footer-bottom-link" target="_blank" href="https://icp.gov.moe/?keyword=20240348" rel="noopener external nofollow" title="萌备">萌ICP备20240348号</a><a class="footer-bottom-link" target="_blank" href="https://beian.miit.gov.cn/" rel="noopener external nofollow" title="工信部备案号">鄂ICP备2023025645号-2</a></div></div><div class="footer-bottom-right"><div id="workboard"><div style="font-size:17px;font-weight:700">本站居然运行了&nbsp;<span id="days">000</span>&nbsp;天&nbsp;<span id="hours">00</span>&nbsp;小时&nbsp;<span id="minutes">00</span>&nbsp;分&nbsp;<span id="seconds">00</span>&nbsp;秒<i class="fas fa-heartbeat" id="heartbeat"></i></div></div><div><a class="footer-bottom-link" target="_blank" href="https://www.aliyun.com/" rel="noopener external nofollow" title="本站通过阿里云ESA提供站点加速与保护">阿里云ESA</a><a class="footer-bottom-link" target="_blank" href="https://hexo.io/zh-cn/" rel="noopener external nofollow" title="本站使用Hexo架构搭建而成">Hexo静态框架</a><a class="footer-bottom-link" target="_blank" href="https://butterfly.js.org/" rel="noopener external nofollow" title="本站由Butterfly主题魔改而成">Butterfly主题</a></div></div></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open rightside-icon"></i><span class="rightside-text">阅读模式</span></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg class="rightside-svg" width="20" height="20" viewBox="0 0 1024 1024"><use id="modeiconT" xlink:href="#icon-moon"></use></svg><span class="rightside-text">亮暗切换</span></a><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse rightside-icon"></i><span class="rightside-text">右键模式</span></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side rightside-icon"></i><span class="rightside-text">更多设置</span></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul rightside-icon"></i><span class="rightside-text">显示目录</span></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes rightside-icon"></i><span class="rightside-text">分享链接</span></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments rightside-icon"></i><span class="rightside-text">直达评论</span></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up rightside-icon"></i><span id="percent">0<span>%</span></span><span class="rightside-text">回到顶部</span></button><button id="go-down" type="button" title="直达底部"><i class="fas fa-arrow-down rightside-icon"></i><span class="rightside-text">直达底部</span></button></div></div><div><script src="/js/utils.js?v=1.8.39"></script><script defer src="/js/main.js?v=1.8.39"></script><script defer src="/js/aimiliy.js?v=1.8.39"></script><script defer src="https://cdn.aimiliy.top/npm/swiper@11.2.6-c/swiper-bundle.min.js"></script><script defer src="https://cdn.aimiliy.top/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script><script defer src="https://cdn.aimiliy.top/npm/masonry-layout@4/masonry.pkgd.min.js"></script><script defer src="https://cdn.aimiliy.top/npm/marked/marked.min.js"></script><script defer src="/js/module.js?v=1.8.39"></script><script async>(()=>{const e=document.body,d=document.getElementById("loading-box"),o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l();let t=!1;window.addEventListener("load",(()=>{t||(o(),t=!0)})),setTimeout((function(){t||(o(),t=!0)}),5e3),btf.addGlobalFn("pjaxSend",l,"preloader_init"),btf.addGlobalFn("pjaxComplete",o,"preloader_end")})()</script><script defer src="https://cdn.aimiliy.top/npm/fancybox@5.0.36/fancybox.umd.min.js"></script><script src="https://cdn.aimiliy.top/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.aimiliy.top/npm/vanilla-lazyload@19.1.3/lazyload.iife.min.js"></script><div class="js-pjax"><span id="fps"><span class="fps-num">FPS：0</span> <span class="fps-des" style="color:#12948b">帧率获取中...😊</span></span><input type="hidden" name="page-type" id="page-type"><script>(()=>{const t=()=>{if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"none"},chtml:{scale:1.1},options:{enableMenu:!0,renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const n=!!e.type.match(/; *mode=display/),a=new t.options.MathItem(e.textContent,t.inputJax[0],n),o=document.createTextNode("");e.parentNode.replaceChild(o,e),a.start={node:o,delim:"",n:0},a.end={node:o,delim:"",n:0},t.math.push(a)}},""]}}};const t=document.createElement("script");t.src="https://cdn.aimiliy.top/npm/mathjax@3.2.2/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}};btf.addGlobalFn("encrypt",t,"mathjax"),window.pjax?t():window.addEventListener("load",t)})()</script><script>(()=>{const o=()=>{twikoo.init({el:document.querySelector("#twikoo-wrap"),envId:"https://twikoo.aimiliy.top",region:"",onCommentLoaded:()=>{btf.loadLightbox(document.querySelectorAll("#twikoo .tk-content img:not(.tk-owo-emotion)"))}})},t=()=>{"object"==typeof twikoo?setTimeout(o,0):getScript("https://cdn.aimiliy.top/npm/twikoo@1.6.44/twikoo.min.js").then(o)};btf.loadComment(document.getElementById("twikoo-wrap"),t)})()</script></div><script async src="https://cdn.aimiliy.top/npm/js/font_958693_aj9baopik47.js"></script><script async src="https://cdn.aimiliy.top/npm/js/font_4662577_e3b7w37hk6i.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><canvas id="visualizer" height="500" width="1500"></canvas><script defer src="https://cdn.aimiliy.top/npm/aplayer@1.10.1/APlayer.min.js"></script><script defer src="https://cdn.aimiliy.top/npm/MetingJS@2.0.1/Meting.min.js"></script><script src="https://cdn.aimiliy.top/npm/pjax@0.2.8/pjax.min.js"></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"])',selectors:['meta[property="og:image"]','meta[property="og:title"]','meta[property="og:url"]','meta[property="og:description"]','meta[property="og:type"]','link[rel="canonical"]',"head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#an_music_bg",".js-pjax",'meta[name="description"]'],cacheBust:!1,analytics:!1,scrollRestoration:!1});const e=e=>{e&&Object.values(e).forEach((e=>e()))};document.addEventListener("pjax:send",(function(){btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");const t=document.body.classList;t.contains("read-mode")&&t.remove("read-mode"),e(window.globalFn.pjaxSend)})),document.addEventListener("pjax:complete",(function(){btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach((e=>{const t=document.createElement("script"),o=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach((e=>t.setAttribute(e.name,e.value))),t.appendChild(document.createTextNode(o)),e.parentNode.replaceChild(t,e)})),(()=>{const e=document.getElementById("page-type");document.body.dataset.type=e.value})(),e(window.globalFn.pjaxComplete)})),document.addEventListener("pjax:error",(e=>{if(404===e.request.status){!0?pjax.loadUrl("/404/"):window.location.href="/404/"}}))})()</script><script async data-pjax src="//cdn.aimiliy.top/npm/busuanzi@2.8.8/busuanzi.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.aimiliy.top/npm/js/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.aimiliy.top/npm/js/instantsearch.production.min.js"></script><script src="/js/search/algolia.js?v=1.8.39"></script></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fas fa-arrow-left right-icon"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fas fa-arrow-right right-icon"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fas fa-refresh right-icon"></i></a><a class="rightMenu-item" href="javascript:btf.rmf.scrollToTop();"><i class="fas fa-arrow-up right-icon"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:btf.rmf.copySelect();"><i class="fas fa-copy right-icon"></i><span class="right-text">复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fas fa-search right-icon"></i><span class="right-text">百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-baiduSearch"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fas fa-link right-icon"></i><span class="right-text">转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:btf.rmf.paste()"><i class="fas fa-copy right-icon"></i><span class="right-text">粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment right-icon"></i><span class="right-text">空降评论</span></a><a class="rightMenu-item" href="javascript:btf.rmf.copyWordsLink()"><i class="fas fa-link right-icon"></i><span class="right-text">复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:btf.rmf.openWithNewTab()"><i class="fas fa-window-restore right-icon"></i><span class="right-text">新窗口打开</span></a><a class="rightMenu-item" id="menu-newOpen" href="javascript:btf.rmf.open()"><i class="fas fa-link right-icon"></i><span class="right-text">转到链接</span></a><a class="rightMenu-item" href="javascript:btf.rmf.copyLink()"><i class="fas fa-copy right-icon"></i><span class="right-text">复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:btf.rmf.saveAs()"><i class="fas fa-download right-icon"></i><span class="right-text">保存图片</span></a><a class="rightMenu-item" href="javascript:btf.rmf.openWithNewTab()"><i class="fas fa-window-restore right-icon"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:btf.rmf.copyLink()"><i class="fas fa-copy right-icon"></i><span class="right-text">复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fas fa-paper-plane right-icon"></i><span class="right-text">随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fas fa-moon right-icon"></i><span class="right-text">昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fas fa-info-circle right-icon"></i><span class="right-text">关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog right-icon"></i><span class="right-text">美化设置</span></a><a class="rightMenu-item" href="javascript:btf.rmf.fullScreen();"><i class="fas fa-expand right-icon"></i><span class="right-text">切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fas fa-solid fa-print right-icon"></i><span class="right-text">打印页面</span></a></div></div><div id="icon-container"></div></div></body></html>